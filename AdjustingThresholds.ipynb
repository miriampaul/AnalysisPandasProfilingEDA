{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/BT2vesULHoQKq0V41IEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miriampaul/AnalysisPandasProfilingEDA/blob/main/AdjustingThresholds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s7JEl__SatJL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data and create a copy\n",
        "LoanData=pd.read_csv(\"/content/01Exercise1.csv\")\n",
        "LoanPrep=LoanData.copy()"
      ],
      "metadata": {
        "id": "3W-Xim-EKIV7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find out the columns with missing values\n",
        "LoanPrep.isnull().sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "fdqZO8-uKRpm",
        "outputId": "5976937c-7516-4c10-f6e7-0a3cad491c0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "married    0\n",
              "ch         0\n",
              "income     0\n",
              "loanamt    0\n",
              "status     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>married</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ch</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loanamt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace missing values , Drop the rows\n",
        "# Assuming you want to drop rows with any missing values from the original data copy\n",
        "LoanPrep = LoanData.copy() # Recreate the DataFrame copy\n",
        "LoanPrep = LoanPrep.dropna()\n",
        "# LoanPrep is now a DataFrame, not a Series"
      ],
      "metadata": {
        "id": "y59vjSw9KauK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop Irrelevant columns based on business sense\n",
        "# Now that LoanPrep is a DataFrame, this operation should work\n",
        "LoanPrep=LoanPrep.drop(['gender'], axis=1)"
      ],
      "metadata": {
        "id": "Xz-v462aKlRS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Dummy Variables\n",
        "LoanPrep.dtypes\n",
        "LoanPrep=pd.get_dummies(LoanPrep, drop_first=True)"
      ],
      "metadata": {
        "id": "fvGl5-BeKtb9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the datta using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar_=StandardScaler()\n",
        "LoanPrep['income']=scalar_.fit_transform(LoanPrep[['income']])\n",
        "LoanPrep['loanamt']=scalar_.fit_transform(LoanPrep[['loanamt']])"
      ],
      "metadata": {
        "id": "N_lAz2F7LZWF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the X and Y Dataframes\n",
        "Y=LoanPrep['status_Y']\n",
        "X=LoanPrep.drop(['status_Y'], axis=1)"
      ],
      "metadata": {
        "id": "M2cMZwccLjcJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the X and Y Dataset into training and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test=\\\n",
        "train_test_split(X, Y, test_size=0.3, random_state=1234, stratify=Y)"
      ],
      "metadata": {
        "id": "lhUZTvAGL_aQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression()\n",
        "lr.fit(X_train, Y_train)\n",
        "Y_predict=lr.predict(X_test)"
      ],
      "metadata": {
        "id": "XURP9IfWMRiN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BUild the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "cm=confusion_matrix(Y_test, Y_predict)\n",
        "score=lr.score(X_test, Y_test)\n",
        "#Get the classication report\n",
        "cr=classification_report(Y_test, Y_predict)\n",
        "score2=accuracy_score(Y_test, Y_predict)"
      ],
      "metadata": {
        "id": "_JVGskSKMmok"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the probabilities of the prediction\n",
        "Y_prob=lr.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "Z4GaOp7VPxtB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VFnim-pP59N",
        "outputId": "7e818add-4d23-4a28-9ced-861b6951dc92"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True,  True,  True, False,  True,  True, False,\n",
              "        True,  True, False,  True, False, False,  True,  True,  True,\n",
              "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True, False, False,  True,  True,  True, False,\n",
              "        True,  True, False,  True,  True,  True,  True,  True, False,\n",
              "       False,  True,  True,  True,  True, False,  True, False,  True,\n",
              "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
              "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
              "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "       False,  True,  True, False,  True,  True,  True, False, False,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True, False,  True,  True,  True,  True, False,  True,\n",
              "        True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgX17rkUP90Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}